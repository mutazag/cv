{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597022398006",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.10.0\n"
    }
   ],
   "source": [
    "import json\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Dataset, Environment, Experiment\n",
    "from azureml.data import FileDataset\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "\n",
    "print(azureml.core.VERSION)\n",
    "version = dict(zip(['major','minor','patch'], azureml.core.VERSION.split('.')))\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metadata dataset \n",
    "\n",
    "\n",
    "metdata dataset will be used to pass metadata information about the images as a side input to parallel run step. this file need to be mounted on every node of the cluster and hence why side input is being used. \n",
    "\n",
    "the data set will point to the root of the metadata folder\n",
    "\n",
    "file name is passed in as an argument to the python parallel run step\n",
    "\n",
    "python entry script can then point to the file on the mounted folder and load the metadata as a pandas dataframe\n",
    "\n",
    "since the path to metadata will change with each run, it will be passed in as a `FileDataset`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'godzilla'\n",
    "if datastore_name in ws.datastores:\n",
    "    datastore = ws.datastores[datastore_name]\n",
    "    if datastore and type(datastore) is Datastore: \n",
    "        print('Found datastore: ' + datastore_name)\n",
    "else: \n",
    "    print('datastore not found...')\n",
    "\n",
    "images_dataset_name = 'images_partition'\n",
    "path_on_datastore = datastore.path('images')\n",
    "input_images_dataset = Dataset.File.from_files(path=path_on_datastore, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{\n  \"source\": [\n    \"('godzilla', 'metadata')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"c2a04b5d-a5e1-4adb-92ad-5055edce627c\",\n    \"name\": \"metadata_ds\",\n    \"version\": 1,\n    \"description\": \"anpr input images metadata\",\n    \"workspace\": \"Workspace.create(name='magaml', subscription_id='907c8efc-c2c8-4c49-a4e1-aeb880e10c88', resource_group='aml')\"\n  }\n}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "metadata_ds = Dataset.File.from_files(path=[(datastore, 'metadata')])\n",
    "metadata_ds.register(workspace=ws, name='metadata_ds', description='anpr input images metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['/20200810_images.csv', '/images_20200810.csv']"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "metadata_ds.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['/20200810_images.csv', '/images_20200810.csv']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ds1 = Dataset.get_by_name(workspace=ws, name='metadata_ds')\n",
    "ds1.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}